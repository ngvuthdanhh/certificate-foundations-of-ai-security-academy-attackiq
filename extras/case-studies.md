# ðŸ“‚ Case Studies â€“ AI Security

## 1. Microsoft Tay Chatbot (2016)
- Attackers exploited **data poisoning** via Twitter.
- Bot began generating offensive outputs within 24 hours.
- Lesson: Without robust input filtering, AI can be manipulated.

## 2. Evasion in Malware Detection
- Adversarially modified malware samples evade ML-based AV.
- Example: Slightly altered binary signatures fool classifiers.
- Lesson: Adversarial training and ensemble models can reduce risk.

## 3. Tesla Autopilot Attack
- Researchers modified **stop signs with stickers**.
- System failed to recognize them correctly.
- Lesson: Physical-world adversarial attacks are practical threats.

## 4. GPT-3 Prompt Injection
- Malicious instructions embedded in prompts cause **jailbreaks**.
- Lesson: LLMs require careful guardrails & monitoring.
