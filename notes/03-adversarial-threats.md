# ⚔️ Module 3 – Adversarial Threats

## Types of Threats
1. **Evasion Attacks**
   - Adversarial examples fooling models at inference.
   - Example: Modifying malware samples to bypass detection.

2. **Poisoning Attacks**
   - Compromised training datasets.
   - Example: Injecting mislabeled images to degrade accuracy.

3. **Model Extraction & Stealing**
   - Query-based attacks to replicate decision boundaries.

## Reflection
Attackers exploit the **opacity of ML models** and their reliance on statistical patterns.
